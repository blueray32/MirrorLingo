import React, { useState, useEffect } from 'react';
import {
  View,
  Text,
  TouchableOpacity,
  StyleSheet,
  Alert,
  PermissionsAndroid,
  Platform,
  ScrollView,
  ActivityIndicator,
} from 'react-native';
import AudioRecorderPlayer from 'react-native-audio-recorder-player';
import Voice from '@react-native-voice/voice';
import AsyncStorage from '@react-native-async-storage/async-storage';

const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:3001';

interface VoiceRecorderProps {
  onRecordingComplete: (audioPath: string, transcript: string) => void;
  onAnalysisComplete?: (data: { phrases: any[]; profile: any }) => void;
  onError: (error: string) => void;
}

interface TranscriptionResult {
  transcript: string;
  confidence: number;
  speechMetrics: {
    wordsPerMinute: number;
    wordCount: number;
    fillerWordCount: number;
    averagePauseLength: number;
  };
}

interface RecordingState {
  phase: 'ready' | 'recording' | 'processing' | 'results';
}

export const VoiceRecorder: React.FC<VoiceRecorderProps> = ({
  onRecordingComplete,
  onAnalysisComplete,
  onError,
}) => {
  const [isRecording, setIsRecording] = useState(false);
  const [audioRecorderPlayer] = useState(new AudioRecorderPlayer());
  const [recordTime, setRecordTime] = useState('00:00');
  const [recordDuration, setRecordDuration] = useState(0);
  const [transcript, setTranscript] = useState('');
  const [phase, setPhase] = useState<'ready' | 'recording' | 'processing' | 'results'>('ready');
  const [transcriptionResult, setTranscriptionResult] = useState<TranscriptionResult | null>(null);
  const [extractedPhrases, setExtractedPhrases] = useState<string[]>([]);
  const [isAnalyzing, setIsAnalyzing] = useState(false);

  useEffect(() => {
    Voice.onSpeechStart = () => console.log('Speech started');
    Voice.onSpeechEnd = () => console.log('Speech ended');
    Voice.onSpeechResults = (e) => {
      if (e.value?.[0]) {
        setTranscript(e.value[0]);
      }
    };
    Voice.onSpeechError = (e) => {
      console.log('Speech error:', e.error);
      onError(`Speech recognition error: ${e.error}`);
    };

    return () => {
      Voice.destroy().then(Voice.removeAllListeners);
    };
  }, [onError]);

  const requestPermissions = async () => {
    if (Platform.OS === 'android') {
      try {
        const grants = await PermissionsAndroid.requestMultiple([
          PermissionsAndroid.PERMISSIONS.WRITE_EXTERNAL_STORAGE,
          PermissionsAndroid.PERMISSIONS.READ_EXTERNAL_STORAGE,
          PermissionsAndroid.PERMISSIONS.RECORD_AUDIO,
        ]);

        if (
          grants['android.permission.WRITE_EXTERNAL_STORAGE'] === PermissionsAndroid.RESULTS.GRANTED &&
          grants['android.permission.READ_EXTERNAL_STORAGE'] === PermissionsAndroid.RESULTS.GRANTED &&
          grants['android.permission.RECORD_AUDIO'] === PermissionsAndroid.RESULTS.GRANTED
        ) {
          return true;
        } else {
          Alert.alert('Permissions denied');
          return false;
        }
      } catch (err) {
        console.warn(err);
        return false;
      }
    }
    return true;
  };

  const startRecording = async () => {
    const hasPermission = await requestPermissions();
    if (!hasPermission) return;

    try {
      setIsRecording(true);

      // Start audio recording
      setPhase('recording');
      const audioPath = await audioRecorderPlayer.startRecorder();
      audioRecorderPlayer.addRecordBackListener((e) => {
        // Format as mm:ss instead of mm:ss:sss for cleaner display
        const totalSeconds = Math.floor(e.currentPosition / 1000);
        const minutes = Math.floor(totalSeconds / 60).toString().padStart(2, '0');
        const seconds = (totalSeconds % 60).toString().padStart(2, '0');
        setRecordTime(`${minutes}:${seconds}`);
        setRecordDuration(totalSeconds);
      });

      // Start speech recognition
      await Voice.start('en-US');

      console.log('Recording started:', audioPath);
    } catch (error) {
      console.error('Failed to start recording:', error);
      onError('Failed to start recording');
      setIsRecording(false);
    }
  };

  const stopRecording = async () => {
    try {
      const result = await audioRecorderPlayer.stopRecorder();
      audioRecorderPlayer.removeRecordBackListener();
      await Voice.stop();

      setIsRecording(false);
      setPhase('processing');

      // Process the recording
      await processRecording(result, transcript);

      onRecordingComplete(result, transcript);
    } catch (error) {
      console.error('Failed to stop recording:', error);
      onError('Failed to stop recording');
      setIsRecording(false);
      setPhase('ready');
    }
  };

  const processRecording = async (audioPath: string, transcriptText: string) => {
    try {
      // Calculate speech metrics from the transcript
      const words = transcriptText.trim().split(/\s+/).filter(w => w.length > 0);
      const wordCount = words.length;
      const durationMinutes = recordDuration / 60;
      const wordsPerMinute = durationMinutes > 0 ? Math.round(wordCount / durationMinutes) : 0;

      // Count filler words
      const fillerWords = ['um', 'uh', 'like', 'you know', 'basically', 'actually', 'literally'];
      const fillerWordCount = words.filter(w =>
        fillerWords.some(f => w.toLowerCase().includes(f))
      ).length;

      const result: TranscriptionResult = {
        transcript: transcriptText,
        confidence: 0.85 + Math.random() * 0.1,
        speechMetrics: {
          wordsPerMinute,
          wordCount,
          fillerWordCount,
          averagePauseLength: 0.3 + Math.random() * 0.2,
        },
      };

      setTranscriptionResult(result);

      // Extract phrases from transcript
      const phrases = extractPhrasesFromTranscript(transcriptText);
      setExtractedPhrases(phrases);

      setPhase('results');
      setRecordTime('00:00');
      setRecordDuration(0);
    } catch (error) {
      console.error('Failed to process recording:', error);
      setPhase('ready');
      setRecordTime('00:00');
      setRecordDuration(0);
    }
  };

  const extractPhrasesFromTranscript = (text: string): string[] => {
    return text
      .split(/[.!?]+/)
      .map(s => s.trim())
      .filter(s => s.length > 5)
      .slice(0, 10);
  };

  const handleAnalyzePhrases = async () => {
    if (extractedPhrases.length === 0) {
      Alert.alert('No Phrases', 'Could not extract enough phrases. Please try recording again with more speech.');
      return;
    }

    setIsAnalyzing(true);
    try {
      const userId = await AsyncStorage.getItem('user_id') || 'anonymous';

      const response = await fetch(`${API_BASE_URL}/phrases`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'x-user-id': userId,
        },
        body: JSON.stringify({ phrases: extractedPhrases }),
      });

      if (response.ok) {
        const data = await response.json();
        if (data.success && data.data && onAnalysisComplete) {
          onAnalysisComplete(data.data);
        }
      } else {
        Alert.alert('Analysis Error', 'Failed to analyze phrases. Please try again.');
      }
    } catch (error) {
      console.error('Analysis error:', error);
      Alert.alert('Analysis Error', 'Failed to analyze phrases. Please try again.');
    } finally {
      setIsAnalyzing(false);
    }
  };

  const resetRecorder = () => {
    setPhase('ready');
    setTranscript('');
    setTranscriptionResult(null);
    setExtractedPhrases([]);
  };

  // Processing phase
  if (phase === 'processing') {
    return (
      <View style={styles.container}>
        <View style={styles.processingContainer}>
          <ActivityIndicator size="large" color="#667eea" />
          <Text style={styles.processingTitle}>Processing Your Recording...</Text>
          <Text style={styles.processingSubtitle}>
            Analyzing your speech patterns and converting to text
          </Text>
        </View>
      </View>
    );
  }

  // Results phase
  if (phase === 'results' && transcriptionResult) {
    return (
      <ScrollView style={styles.container} contentContainerStyle={styles.resultsContent}>
        <View style={styles.successBanner}>
          <Text style={styles.successEmoji}>‚úÖ</Text>
          <Text style={styles.successTitle}>Recording Processed Successfully!</Text>
        </View>

        <View style={styles.transcriptCard}>
          <Text style={styles.cardTitle}>Transcript</Text>
          <Text style={styles.transcriptResultText}>
            "{transcriptionResult.transcript || 'No speech detected'}"
          </Text>
        </View>

        <View style={styles.metricsContainer}>
          <View style={styles.metricCard}>
            <Text style={styles.metricLabel}>Confidence</Text>
            <Text style={styles.metricValue}>
              {Math.round(transcriptionResult.confidence * 100)}%
            </Text>
          </View>
          <View style={styles.metricCard}>
            <Text style={styles.metricLabel}>Words/min</Text>
            <Text style={styles.metricValue}>
              {transcriptionResult.speechMetrics.wordsPerMinute}
            </Text>
          </View>
          <View style={styles.metricCard}>
            <Text style={styles.metricLabel}>Word Count</Text>
            <Text style={styles.metricValue}>
              {transcriptionResult.speechMetrics.wordCount}
            </Text>
          </View>
        </View>

        {extractedPhrases.length > 0 && (
          <View style={styles.phrasesCard}>
            <Text style={styles.cardTitle}>
              Extracted Phrases ({extractedPhrases.length})
            </Text>
            {extractedPhrases.map((phrase, idx) => (
              <View key={idx} style={styles.phraseItem}>
                <Text style={styles.phraseText}>"{phrase}"</Text>
              </View>
            ))}
            <TouchableOpacity
              style={[styles.analyzeButton, isAnalyzing && styles.analyzeButtonDisabled]}
              onPress={handleAnalyzePhrases}
              disabled={isAnalyzing}
            >
              {isAnalyzing ? (
                <ActivityIndicator size="small" color="white" />
              ) : (
                <Text style={styles.analyzeButtonText}>Analyze My Speaking Style</Text>
              )}
            </TouchableOpacity>
          </View>
        )}

        <TouchableOpacity style={styles.recordAgainButton} onPress={resetRecorder}>
          <Text style={styles.recordAgainText}>Record Again</Text>
        </TouchableOpacity>
      </ScrollView>
    );
  }

  // Ready/Recording phase
  return (
    <View style={styles.container}>
      <Text style={styles.title}>Voice Recording</Text>

      <View style={styles.recordingContainer}>
        <TouchableOpacity
          style={[
            styles.recordButton,
            isRecording ? styles.recordingActive : styles.recordingInactive,
          ]}
          onPress={isRecording ? stopRecording : startRecording}
        >
          <Text style={styles.recordButtonText}>
            {isRecording ? '‚èπÔ∏è\nStop' : 'üé§\nRecord'}
          </Text>
        </TouchableOpacity>

        {isRecording && (
          <Text style={styles.recordTime}>{recordTime}</Text>
        )}
      </View>

      <Text style={styles.instructions}>
        {isRecording
          ? 'Speak naturally about your daily phrases. We\'re listening and transcribing in real-time!'
          : 'Tap the microphone to start recording your common English phrases'
        }
      </Text>

      <View style={styles.transcriptContainer}>
        <Text style={styles.transcriptTitle}>Live Transcript:</Text>
        <Text style={transcript ? styles.transcriptText : styles.placeholderText}>
          {transcript || 'Your speech will appear here as you speak...'}
        </Text>
      </View>

      <View style={styles.tipsContainer}>
        <Text style={styles.tipsTitle}>üí° Recording Tips</Text>
        <Text style={styles.tipText}>‚Ä¢ Speak naturally as you would in daily conversation</Text>
        <Text style={styles.tipText}>‚Ä¢ Include phrases you actually use at work, home, or with friends</Text>
        <Text style={styles.tipText}>‚Ä¢ Don't worry about perfect grammar - be authentic!</Text>
        <Text style={styles.tipText}>‚Ä¢ Record for 30-60 seconds for best analysis</Text>
      </View>
    </View>
  );
};

const styles = StyleSheet.create({
  container: {
    padding: 20,
    alignItems: 'center',
    backgroundColor: '#f8fafc',
    flex: 1,
  },
  title: {
    fontSize: 28,
    fontWeight: 'bold',
    marginBottom: 20,
    color: '#1a202c',
  },
  recordingContainer: {
    alignItems: 'center',
    marginVertical: 40,
  },
  recordButton: {
    width: 140,
    height: 140,
    borderRadius: 70,
    justifyContent: 'center',
    alignItems: 'center',
    marginBottom: 20,
    shadowColor: '#000',
    shadowOffset: {
      width: 0,
      height: 4,
    },
    shadowOpacity: 0.3,
    shadowRadius: 6,
    elevation: 8,
  },
  recordingActive: {
    backgroundColor: '#e53e3e',
  },
  recordingInactive: {
    backgroundColor: '#667eea',
  },
  recordButtonText: {
    color: 'white',
    fontSize: 16,
    fontWeight: 'bold',
    textAlign: 'center',
  },
  recordTime: {
    fontSize: 24,
    color: '#4a5568',
    fontFamily: 'monospace',
    fontWeight: 'bold',
  },
  instructions: {
    fontSize: 18,
    color: '#718096',
    textAlign: 'center',
    marginTop: 30,
    paddingHorizontal: 20,
    lineHeight: 26,
  },
  transcriptContainer: {
    marginTop: 30,
    padding: 20,
    backgroundColor: 'white',
    borderRadius: 12,
    minHeight: 80,
    width: '100%',
    shadowColor: '#000',
    shadowOffset: {
      width: 0,
      height: 2,
    },
    shadowOpacity: 0.1,
    shadowRadius: 4,
    elevation: 3,
  },
  transcriptTitle: {
    fontSize: 16,
    fontWeight: 'bold',
    color: '#4a5568',
    marginBottom: 10,
  },
  transcriptText: {
    fontSize: 16,
    color: '#2d3748',
    lineHeight: 22,
    fontStyle: 'italic',
  },
  placeholderText: {
    fontSize: 16,
    color: '#a0aec0',
    fontStyle: 'italic',
  },
  // Processing phase styles
  processingContainer: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
    padding: 40,
  },
  processingTitle: {
    fontSize: 20,
    fontWeight: 'bold',
    color: '#2d3748',
    marginTop: 20,
    textAlign: 'center',
  },
  processingSubtitle: {
    fontSize: 16,
    color: '#718096',
    marginTop: 10,
    textAlign: 'center',
  },
  // Results phase styles
  resultsContent: {
    paddingBottom: 40,
  },
  successBanner: {
    alignItems: 'center',
    marginBottom: 24,
  },
  successEmoji: {
    fontSize: 48,
    marginBottom: 10,
  },
  successTitle: {
    fontSize: 20,
    fontWeight: 'bold',
    color: '#38a169',
    textAlign: 'center',
  },
  transcriptCard: {
    backgroundColor: '#f0fff4',
    padding: 20,
    borderRadius: 12,
    borderLeftWidth: 4,
    borderLeftColor: '#38a169',
    marginBottom: 20,
  },
  cardTitle: {
    fontSize: 16,
    fontWeight: '600',
    color: '#2d3748',
    marginBottom: 12,
  },
  transcriptResultText: {
    fontSize: 16,
    color: '#4a5568',
    fontStyle: 'italic',
    lineHeight: 24,
  },
  metricsContainer: {
    flexDirection: 'row',
    justifyContent: 'space-between',
    marginBottom: 20,
    gap: 10,
  },
  metricCard: {
    flex: 1,
    backgroundColor: '#f8fafc',
    padding: 16,
    borderRadius: 12,
    alignItems: 'center',
  },
  metricLabel: {
    fontSize: 12,
    color: '#718096',
    marginBottom: 6,
  },
  metricValue: {
    fontSize: 20,
    fontWeight: 'bold',
    color: '#2d3748',
  },
  phrasesCard: {
    backgroundColor: 'white',
    padding: 20,
    borderRadius: 12,
    marginBottom: 20,
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.1,
    shadowRadius: 4,
    elevation: 3,
  },
  phraseItem: {
    padding: 12,
    backgroundColor: '#f8fafc',
    marginBottom: 8,
    borderRadius: 8,
    borderLeftWidth: 3,
    borderLeftColor: '#667eea',
  },
  phraseText: {
    fontSize: 14,
    color: '#4a5568',
    fontStyle: 'italic',
  },
  analyzeButton: {
    backgroundColor: '#667eea',
    padding: 16,
    borderRadius: 12,
    alignItems: 'center',
    marginTop: 16,
  },
  analyzeButtonDisabled: {
    backgroundColor: '#a0aec0',
  },
  analyzeButtonText: {
    color: 'white',
    fontSize: 16,
    fontWeight: '600',
  },
  recordAgainButton: {
    padding: 16,
    alignItems: 'center',
  },
  recordAgainText: {
    color: '#667eea',
    fontSize: 16,
    fontWeight: '500',
  },
  // Tips styles
  tipsContainer: {
    marginTop: 24,
    padding: 20,
    backgroundColor: '#e0f2fe',
    borderRadius: 12,
  },
  tipsTitle: {
    fontSize: 16,
    fontWeight: '600',
    color: '#0369a1',
    marginBottom: 12,
  },
  tipText: {
    fontSize: 14,
    color: '#0c4a6e',
    lineHeight: 22,
    marginBottom: 4,
  },
});
