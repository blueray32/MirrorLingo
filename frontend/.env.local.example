# Frontend Environment Variables (Next.js)
NEXT_PUBLIC_API_URL=http://localhost:3001
NEXT_PUBLIC_APP_ENV=development

# Ollama AI Configuration (required for conversation practice)
# Make sure Ollama is running: ollama serve
# Pull the model: ollama pull llama3.1:8b
OLLAMA_API_URL=http://localhost:11434/api/chat
OLLAMA_MODEL=llama3.1:8b
